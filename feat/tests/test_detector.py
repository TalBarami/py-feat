import pytest
from feat.detector import Detector
from feat.data import Fex
from huggingface_hub import PyTorchModelHubMixin
import numpy as np
from feat.utils.io import get_test_data_path
import warnings
import os
from feat.utils.io import read_feat
import torch

EXPECTED_FEX_WIDTH = 691


@pytest.mark.usefixtures(
    "single_face_img",
    "single_face_img_data",
    "multi_face_img",
    "multi_face_img_data",
    "no_face_img",
    "single_face_mov",
    "no_face_mov",
    "face_noface_mov",
    "noface_face_mov",
)
class Test_Detector:
    """Test new single model detector"""

    detector = Detector(device="cpu")

    def test_init(self):
        assert isinstance(self.detector, PyTorchModelHubMixin)

    def test_fast_detect(self, single_face_img):
        fex = self.detector.detect(single_face_img)
        assert isinstance(fex, Fex)

        # No bad predictions on default image
        assert not fex.isnull().any().any()

        # Default output is 689 features
        assert fex.shape == (1, EXPECTED_FEX_WIDTH)

        # Bounding box
        assert 150 < fex.FaceRectX[0] < 180
        assert 125 < fex.FaceRectY[0] < 140

        # Jin is smiling
        assert fex.happiness[0] > 0.8

        # AU checks; TODO: Add more
        assert fex.aus.AU20[0] > 0.8

    def test_fast_landmark_with_batches(self, multiple_images_for_batch_testing):
        """
        Make sure that when the same images are passed in with and without batch
        processing, the detected landmarks and poses come out to be the same
        """
        det_result_batch = self.detector.detect(
            inputs=multiple_images_for_batch_testing,
            batch_size=5,
        )

        det_result_no_batch = self.detector.detect(
            inputs=multiple_images_for_batch_testing,
            batch_size=1,
        )

        assert np.allclose(
            det_result_batch.loc[:, "x_0":"y_67"].to_numpy(),
            det_result_no_batch.loc[:, "x_0":"y_67"].to_numpy(),
        )

    # Track progress updates in this issue: https://github.com/cosanlab/py-feat/issues/128
    def test_fast_detection_and_batching_with_diff_img_sizes(
        self, single_face_img, multi_face_img, multiple_images_for_batch_testing
    ):
        """
        Make sure that when the same images are passed in with and without batch
        processing, the detected landmarks and poses come out to be the same
        """
        # Each sublist of images contains different sizes
        all_images = (
            [single_face_img] + [multi_face_img] + multiple_images_for_batch_testing
        )

        # Multiple images with different sizes are ok as long as batch_size == 1
        # Detections will be done in each image's native resolution
        _ = self.detector.detect(inputs=all_images, batch_size=1)

        # If batch_size > 1 then output_size must be set otherwise we can't stack to make a
        # tensor
        with pytest.raises(ValueError):
            _ = self.detector.detect(
                inputs=all_images,
                batch_size=5,
            )

        # Here we batch by resizing each image to 256xpadding
        batched = self.detector.detect(inputs=all_images, batch_size=5, output_size=256)

        # We can also forcibly resize images even if we don't batch process them
        nonbatched = self.detector.detect(
            inputs=all_images, batch_size=1, output_size=256
        )

        # To make sure that resizing doesn't interact unexpectedly with batching, we should
        # check that the detections we get back for the same sized images are the same when
        # processed as a batch or serially. We check each column separately
        au_diffs = np.abs(batched.aus - nonbatched.aus).max()
        TOL = 0.5
        bad_aus = au_diffs[au_diffs > TOL]
        if len(bad_aus):
            warnings.warn(
                f"Max AU deviation is larger than tolerance ({TOL}) when comparing batched vs non-batched detections: {bad_aus}"
            )
        else:
            print(
                f"Max AU deviation (batched - nonbatched): {au_diffs.idxmax()}: {au_diffs.max()}"
            )

    def test_fast_init_with_wrongmodelname(self):
        """Should fail with unsupported model name"""
        with pytest.raises(ValueError):
            _ = Detector(emotion_model="badmodelname")

    def test_fast_nofile(self):
        """Should fail with missing data"""
        with pytest.raises((FileNotFoundError, RuntimeError)):
            inputFname = os.path.join(get_test_data_path(), "nosuchfile.jpg")
            _ = self.detector.detect(inputFname)

    # no face images

    def test_fast_detect_single_img_no_face(self, no_face_img):
        """Test detection of a single image with no face. Default detector returns EXPECTED_FEX_WIDTH attributes"""
        out = self.detector.detect(no_face_img)
        assert isinstance(out, Fex)
        assert out.shape == (1, EXPECTED_FEX_WIDTH)
        assert np.isnan(out.happiness.values[0])

    def test_fast_detect_multi_img_no_face(self, no_face_img):
        """Test detection of a multiple images with no face. Default detector returns EXPECTED_FEX_WIDTH attributes"""
        out = self.detector.detect([no_face_img] * 3)
        assert out.shape == (3, EXPECTED_FEX_WIDTH)

    def test_fast_detect_multi_img_no_face_batching(self, no_face_img):
        """Test detection of a multiple images with no face. Default detector returns EXPECTED_FEX_WIDTH attributes"""
        out = self.detector.detect([no_face_img] * 5, batch_size=2)
        assert out.shape == (5, EXPECTED_FEX_WIDTH)

    def test_fast_detect_multi_img_mixed_no_face(
        self, no_face_img, single_face_img, multi_face_img
    ):
        """Test detection of a single image with no face. Default detector returns EXPECTED_FEX_WIDTH attributes"""
        out = self.detector.detect([single_face_img, no_face_img, multi_face_img] * 2)
        assert out.shape == (14, EXPECTED_FEX_WIDTH)

    def test_fast_detect_multi_img_mixed_no_face_batching(
        self, no_face_img, single_face_img, multi_face_img
    ):
        """Test detection of a single image with no face. Default detector returns EXPECTED_FEX_WIDTH attributes"""
        out = self.detector.detect(
            [single_face_img, no_face_img, multi_face_img] * 2,
            batch_size=4,
            output_size=300,
        )
        assert out.shape == (14, EXPECTED_FEX_WIDTH)

    # Single images
    def test_fast_detect_single_img_single_face(self, single_face_img):
        """Test detection of single face from single image. Default detector returns EXPECTED_FEX_WIDTH attributes"""
        out = self.detector.detect(single_face_img)
        assert isinstance(out, Fex)
        assert out.shape == (1, EXPECTED_FEX_WIDTH)
        assert out.happiness.values[0] > 0

    def test_fast_detect_single_img_multi_face(self, multi_face_img):
        """Test detection of multiple faces from single image"""
        out = self.detector.detect(multi_face_img)
        assert isinstance(out, Fex)
        assert out.shape == (5, EXPECTED_FEX_WIDTH)

    def test_fast_detect_with_alpha(self):
        image = os.path.join(get_test_data_path(), "Image_with_alpha.png")
        _ = self.detector.detect(image)

    # Multiple images
    def test_fast_detect_multi_img_single_face(self, single_face_img):
        """Test detection of single face from multiple images"""
        out = self.detector.detect([single_face_img, single_face_img])
        assert out.shape == (2, EXPECTED_FEX_WIDTH)

    def test_fast_detect_multi_img_multi_face(self, multi_face_img):
        """Test detection of multiple faces from multiple images"""
        out = self.detector.detect([multi_face_img, multi_face_img])
        assert out.shape == (10, EXPECTED_FEX_WIDTH)

    def test_fast_detect_images_with_batching(self, single_face_img):
        """Test if batching works by passing in more images than the default batch size"""

        out = self.detector.detect([single_face_img] * 6, batch_size=5)
        assert out.shape == (6, EXPECTED_FEX_WIDTH)

    def test_fast_detect_mismatch_image_sizes(self, single_face_img, multi_face_img):
        """Test detection on multiple images of different sizes with and without batching"""

        out = self.detector.detect([multi_face_img, single_face_img])
        assert out.shape == (6, EXPECTED_FEX_WIDTH)

        out = self.detector.detect(
            [multi_face_img, single_face_img] * 5, batch_size=5, output_size=512
        )
        assert out.shape == (30, EXPECTED_FEX_WIDTH)

    def test_fast_detect_video(
        self, single_face_mov, no_face_mov, face_noface_mov, noface_face_mov
    ):
        """Test detection on video file"""
        out = self.detector.detect(single_face_mov, skip_frames=24, data_type="video")
        assert len(out) == 3
        assert out.happiness.values.max() > 0

        # Test no face movie
        out = self.detector.detect(no_face_mov, skip_frames=24, data_type="video")
        assert len(out) == 4
        # Empty detections are filled with NaNs
        assert out.happiness.isnull().all().all()

        # Test mixed movie, i.e. spliced vids of face -> noface and noface -> face
        out = self.detector.detect(face_noface_mov, skip_frames=24, data_type="video")
        assert len(out) == 3 + 4 + 1
        # first few frames have a face
        assert not out.happiness.iloc[:3].isnull().all().all()
        # But the rest are from a diff video that doesn't
        assert out.happiness.iloc[3:].isnull().all().all()

        out = self.detector.detect(noface_face_mov, skip_frames=24, data_type="video")
        assert len(out) == 3 + 4 + 1
        # beginning no face
        assert out.happiness.iloc[:4].isnull().all().all()
        # middle frames have face
        assert not out.happiness.iloc[4:7].isnull().all().all()
        # ending doesn't
        assert out.happiness.iloc[7:].isnull().all().all()

    def test_save_detect(self, single_face_mov, tmp_path):
        """Test appending to file during detection"""

        out = self.detector.detect(
            single_face_mov, skip_frames=12, data_type="video", save=tmp_path / "test.csv"
        )
        assert (tmp_path / "test.csv").exists()
        df = read_feat(tmp_path / "test.csv")
        assert df.equals(out)
        out_nosave = self.detector.detect(
            single_face_mov, skip_frames=12, data_type="video"
        )
        # We're not enforcing dtypes so the output Fex from .detect()
        # uses Float32, but read_feat() uses Float64
        # So instead we check the numeric values are close, columns match,
        #  and shapes, match
        np.allclose(out._get_numeric_data(), out_nosave._get_numeric_data())
        np.allclose(df._get_numeric_data(), out_nosave._get_numeric_data())
        assert all(df.columns == out_nosave.columns) and all(df.columns == out.columns)
        assert df.shape == out_nosave.shape == out.shape

    def test_detect_tensor(self, single_face_img_data):
        tensor = torch.stack([single_face_img_data] * 3)
        tensor.shape
        fex = self.detector.detect(tensor, data_type="tensor")
        assert fex.shape == (3, EXPECTED_FEX_WIDTH)
